{
 "metadata": {
  "name": "",
  "signature": "sha256:4322b67e742e06d196f0b424562da2b968366af05abc6d89dc5623293ade0104"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# BigQuery - Using Asynchronous APIs\n",
      "\n",
      "This notebook demonstrates how to use asynchronous versions of the pygcp.bigquery APIs from within a notebook.\n",
      "\n",
      "### In this notebook you will\n",
      "* Learn about the Query and Table APIs that have \\*_async versions\n",
      "* Learn how to use these APIs to return quickly so you can continue to do other work\n",
      "* Learn how to monitor the state of background async tasks and know when they are complete\n",
      "\n",
      "Related Links:\n",
      "\n",
      "* [BigQuery](https://cloud.google.com/bigquery/)\n",
      "\n",
      "----\n",
      "\n",
      "NOTE:\n",
      "\n",
      "* If you're new to notebooks, or want need an introduction to using BigQuery, check out the full [list](..) of notebooks.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import gcp.bigquery as bq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Many if the APIs that exist on Query and Table objects in the gcp.bigquery library have async forms.\n",
      "\n",
      "These include:\n",
      "\n",
      "* Query.extract\n",
      "* Query.to_file\n",
      "* Query.execute\n",
      "* Table.load\n",
      "* Table.extract\n",
      "* Table.to_file\n",
      "* View.execute\n",
      "\n",
      "In each case, the signature is exactly the same; the only difference is that the async versions have an \\_async suffix on the method name and return Job objects.\n",
      "\n",
      "For example, the code below will attempt to extract the first 1000 rows of the natality sample table to a temporary file:\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t = bq.table('publicdata:samples.natality')\n",
      "j = t.sample(count=1000).to_file_async('/tmp/natality1000.csv')\n",
      "j"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "Job 644ad0d6-366f-4578-922a-40cd1aac9d34 in progress"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice how the extract\\_async method returned a job with a GUID ID and a status. For a correct job on a very fast \n",
      "machine you may see 'completed' for the job status, but more likely you see 'in progress'.\n",
      "\n",
      "You can always check on the state of a job object by calling its is\\_complete method:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "j.is_complete"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "False"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To wait until a job completes we can call wait():"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "j.wait()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "Job 644ad0d6-366f-4578-922a-40cd1aac9d34 completed"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Once it is complete, the fatal\\_error property will tell us if a job failed, while the errors property will inform us of any non-fatal errors that may have occurred:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Fatal: %s\" % str(j.fatal_error)\n",
      "print \"Non-fatal: %s\" % str(j.errors)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fatal: None\n",
        "Non-fatal: None\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Similarly, we can call the Job.failed method to test for success:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "j.failed"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "False"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "To see what happens with a failing job we can try a similar operation but with an extract using an invalid GCS name:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "try:\n",
      "  t = bq.table('publicdata:samples.natality')\n",
      "  j = t.sample(count=1000).extract_async('natality:1000.csv')\n",
      "except Exception as e:\n",
      "  print \"%s: %s\" % (str(type(e)), e)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'gcp._util._job.JobError'>: Invalid extract destination URI 'natality:1000.csv'. Must be a valid Google Storage path.\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notice how in this case we got a JobError exception.\n",
      "\n",
      "There are two useful utility functions in gcp.bigquery available for working with jobs, namely wait_any and wait_all. Each of these can take a reference to a job, or a list of jobs, plus an optional timeout. wait_any will return when at least one job has completed (or a timeout happens) while wait_all will return when all jobs have completed (or the timeout happens). In each case the return value is the list of complete jobs. We can illustrate this with the following code:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "q1 = bq.query('SELECT * FROM [publicdata:samples.natality] LIMIT 200')\n",
      "q2 = bq.query('SELECT * FROM [publicdata:samples.natality] LIMIT 2000')\n",
      "j1 = q1.execute_async(use_cache=False)\n",
      "j2 = q2.execute_async(use_cache=False)\n",
      "\n",
      "while True:\n",
      "    completed = bq.wait_any([j1, j2])\n",
      "    print str(completed)\n",
      "    if len(completed) == 2:\n",
      "        break\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[Job job_sf_Bh7-kj-NcJay6sHGxV7sItKU completed]\n",
        "[Job job_sf_Bh7-kj-NcJay6sHGxV7sItKU completed]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[Job job_sf_Bh7-kj-NcJay6sHGxV7sItKU completed, Job job_cI_A2CaMMWItebQMrRug3l5PWKE completed]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    }
   ],
   "metadata": {}
  }
 ]
}