{
 "metadata": {
  "name": "",
  "signature": "sha256:b1c16353f876ac8bc3b292bdea546977b345e6dd4e61159e9bbf1174493922d0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# BigQuery - Building and Testing a Simple Deployable Pipeline\n",
      "\n",
      "This notebook builds on the earlier BigQuery notebooks to introduce you to the cell magics used to define a deployable pipeline of BigQuery tasks.\n",
      "\n",
      "The %bigquery cell magics you have seen so far are useful for exploratory data analysis in the notebook. However, you may want to use the notebook to build a query that you schedule for regular execution. DataLab has special %bqmodule variants of the %bigquery magics to specify these queries, and this notebook will introduce the simplest form.\n",
      "\n",
      "In this notebook you will see:\n",
      "\n",
      "* how to define command line arguments and their default values for deployable pipelines with '%bqmodule arguments', including using the special types for table names and formatted date strings\n",
      "* how to define SQL queries for these pipelines that make use of the arguments using '%bqmodule sql'\n",
      "* how to test the hermeticity of a pipeline with sample argument values using '%bqmodule run'\n",
      "* how to override variable values in the notebook itself to aid in testing pipeline queries, using regular Python code and '%bigquery run'\n",
      "* how to define table wildcards that can be substituted for in the notebook for testing purposes using '%bqmodule source'\n",
      "\n",
      "\n",
      "----\n",
      "\n",
      "NOTE:\n",
      "\n",
      "* If you're new to notebooks, or want to check out additional samples, check out the full [list](..) of notebooks."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import gcp.bigquery as bq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The most important %bqmodule cell magic is %bqmodule sql. Just like %bigquery sql, this allows you to define and name a BigQuery SQL query:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bqmodule sql\n",
      "select * from [cloud-datalab:sampledata.requestlogs_20140615] limit 10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "ERROR: Cell magic `%%bqmodule` not found.\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are some differences, however, and above you can see the first. For bqmodule, the --name argument is *required*. This is because bqmodule SQLs are never executed immediately, but must be used within other queries or executed using %bqmodule run, as we will see shortly. So let's give our query a name:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bqmodule sql --name log\n",
      "select * from [cloud-datalab:sampledata.requestlogs_20140615] limit 10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "ERROR: Cell magic `%%bqmodule` not found.\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This will define our query but instead of existing at the top-level it exists in a special module just for bqmodule entities.\n",
      "\n",
      "Now we have named the query, we can use it in other queries as a source. We can run it, but to do so, we need to use a special magic, bqmodule run:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%bqmodule run log"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "ERROR: Line magic function `%bqmodule` not found.\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Another way in which bqmodule queries are different is in variable substitution. A variable reference in a bqmodule sql magic must either reference a previously defined bqmodule sql (or, as we will see later, a bqmodule source), or it must reference a defined *argument*. We define arguments with the %bqmodule arguments magic. Note that a %bqmodule arguments magic can define many arguments, but a pipeline can only have one %bqmodule arguments magic (more precisely, executing a %bqmodule arguments magic will clobber a previous %bqmodule arguments magic, so you should only use one)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bqmodule arguments\n",
      "arg('logfile', default='cloud-datalab:sampledata.requestlogs_20140615', type=table, help='the name of the table to query')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "ERROR: Cell magic `%%bqmodule` not found.\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bqmodule sql --name log2\n",
      "select * from $logfile limit 10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "ERROR: Cell magic `%%bqmodule` not found.\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's test this:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%bqmodule run log2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "ERROR: Line magic function `%bqmodule` not found.\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can see what the SQL is that will execute by using the -d or --dry argument to bqmodule run:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%bqmodule run -d log2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "ERROR: Line magic function `%bqmodule` not found.\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It's worth noting that we can reference %bqmodule sqls from %bigquery sqls, and if we do so the query will execute in the context of the notebook. Observe below how we redefine logfile and then run the query by nesting it in a %bigquery sql select statement:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logfile = bq.table('cloud-datalab:sampledata.requestlogs_20140616')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bigquery sql\n",
      "select * from $log2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndexError",
       "evalue": "list index out of range",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-10-3413e79ca009>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'bigquery'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu'sql'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu'select * from $log2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m/Users/gram/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2160\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2162\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2163\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/gram/datalab/sources/sdk/pygcp/gcp/interactive/_bigquery.py\u001b[0m in \u001b[0;36mbigquery\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    241\u001b[0m   \u001b[0;31m# TODO(gram): Fix this hack!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m   \u001b[0mnamespace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_notebook_environment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'pipeline'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m     \u001b[0mnamespace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_pipeline_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mIndexError\u001b[0m: list index out of range"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However, changing the value of variables like logfile in the notebook will not affect the query when run using bqmodule run. This is because bqmodule run is meant to test the deployable notebook, and the notebook execution environment is not part of deployment. *Only bqmodule magics are used in deployment, and the result must be hermetic (self-contained).*\n",
      "\n",
      "You can test different values for the arguments by specifying them as command line arguments in the bqmodule run cell body:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bqmodule run log2\n",
      "--logfile 'cloud-datalab:sampledata.requestlogs_20140620'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As a convenience, there is a bigquery run cell magic that is much the same as bqmodule run except it allows overriding in the IPython environment. So we can do the equivalent to the above test this way:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logfile = bq.table('cloud-datalab:sampledata.requestlogs_20140620')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%bigquery run log2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In practice, we would normally want to generate the name of the file based on the date. We can do this using some additional parameters to the arg() calls in the arguments magic, namely by changing the default value to 'today', and applying a format string and offset. The format strings make use of the standrd Python strftime function, while offsets can be specified as a comma-separated sequence of quantity-unit pairs, where the unit can be one of y, m, d, h, s for year, month, day, hour and minute respectively. The following argument will default to one year ago from today, and generate the file name for us:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bqmodule arguments\n",
      "arg('logfile', default='today', offset='-1y', format='cloud-datalab:sampledata.requestlogs_%Y%m%d', type=table, help='the name of the table to query')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We show the resulting SQL only, rather than executing the query, as the table may not exist in this sample:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%bqmodule run -d log2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Arguments can be particularly useful for defining table wildcards, such as in the example below:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bqmodule arguments\n",
      "arg('logfile', default='mydata.logs', help='the prefix for the source tables')\n",
      "arg('start', default='today', offset='-7d', format='%Y-%m-%d', help='the start of the range')\n",
      "arg('end', default='yesterday', format='%Y-%m-%d', help='the end of the range')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bqmodule sql --name rangequery\n",
      "select * from (TABLE_DATE_RANGE($logfile, TIMESTAMP($start), TIMESTAMP($end)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%bqmodule run -d rangequery"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When using wildcards, for testing in the notebook it may be useful to use them in conjunction with a bqmodule source magic. The latter can be used to define a named SQL fragment such as a table wildcard expression that can then be referenced from a query. In the notebook we can then test by subtituting a single table for the entire wildcard by redefining the name.\n",
      "\n",
      "When doing a bqmodule run, bqmodule sources are expanded first before they are substituted in sqls so that any variables they reference are expanded before they in turn are used to expand the query. In the example below we will use a bqmodule source to define the table wildcard and adjust our query appropriately:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bqmodule source tables\n",
      "TABLE_DATE_RANGE($logfile, TIMESTAMP($start), TIMESTAMP($end))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bqmodule sql --name rangequery\n",
      "select * from $tables"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can see that the SQL expands to the same:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%bqmodule run -d rangequery"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However, we can now override the entire table wildcard expression with just a test table in the notebook, and test with bigquery run:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Override and test with just one table\n",
      "tables = bq.table('mydata.logs20150601')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%bigquery run -d rangequery"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally, we should reiterate that when building and testing a pipeline you would normally have only a single bqmodule arguments magic near the start, one or more bqmodule source and bqmodule sql magics, and finally a bqmodule run magic. In this notebook we have flouted those conventions to illustrate the principles behind the magics."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}